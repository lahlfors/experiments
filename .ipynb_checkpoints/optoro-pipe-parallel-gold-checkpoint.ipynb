{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebfc5822-2a79-4e4f-aa3c-b7756b0b9d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp.v2.dsl import (\n",
    "    component,\n",
    "    Output,\n",
    "    OutputPath,\n",
    "    Model,\n",
    "    Input,\n",
    "    InputPath,\n",
    "    ParallelFor,\n",
    "    pipeline,\n",
    "    Condition\n",
    "    )\n",
    "from kfp.v2 import compiler\n",
    "\n",
    "\n",
    "\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from google.cloud import aiplatform as aip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7fde04b-b4c4-4437-a8f5-7d60e6bcddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import kfp.components as components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b67023a7-57a0-402d-a2cd-f1f82e6ea52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_URI='gs://laah-playaip-20220822213353'\n",
    "PROJECT_ID='laah-play'\n",
    "PIPELINE_ROOT = \"{}/pipeline_root/bikes_weather\".format(BUCKET_URI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b0892d4-9089-41b6-a33f-f7acda99592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24a8e0a6-c57b-4ea5-9366-8474c7c6e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"pandas\", \n",
    "                         \"google-cloud-aiplatform\", \n",
    "                         \"google-cloud-bigquery-storage\",\n",
    "                         \"google-cloud-bigquery\",\n",
    "                         \"pyarrow\"]\n",
    ")\n",
    "def preprocess(in_bigquery_projectid:str, \n",
    "               in_bigquery_dataset:str, \n",
    "               output_csv_path: OutputPath('CSV_DATASET')):\n",
    "    #1\n",
    "    from google.cloud import bigquery\n",
    "    import google.auth\n",
    "    \n",
    "    creds, project = google.auth.default()\n",
    "    client = bigquery.Client(project=in_bigquery_projectid, credentials=creds)\n",
    "\n",
    "    query =     \"\"\"\n",
    "            SELECT * FROM `laah-play.telco.churn`\n",
    "    \"\"\"\n",
    "    print(query)\n",
    "    \n",
    "    dataframe = client.query(query).to_dataframe()\n",
    "    print(dataframe.head())\n",
    "    \n",
    "    dataframe.to_csv(output_csv_path)\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4cf185f-df79-4cef-8cca-99739335a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "   packages_to_install=[\"pandas\", \"scikit-learn==1.0\", \"google-cloud-aiplatform\"], base_image = \"python:3.7\"\n",
    ")\n",
    "def train(in_experiment_name:str, \n",
    "          in_experiment_training_set: str,\n",
    "          in_vertexai_region: str, \n",
    "          in_vertexai_projectid: str, \n",
    "          in_csv_path: InputPath('CSV_DATASET'), \n",
    "          model_type: str, \n",
    "          saved_model: Output[Model]\n",
    "         ):\n",
    "    \n",
    "    import pandas as pd  \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import sklearn.metrics as metrics\n",
    "    from google.cloud import aiplatform\n",
    "    from datetime import datetime\n",
    "    import pickle\n",
    "    import os\n",
    "    import random\n",
    "    idn = random.randint(0,1000)\n",
    "    \n",
    "    from google.cloud import storage\n",
    "\n",
    "\n",
    "    df = pd.read_csv(in_csv_path)\n",
    "    \n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype=='object':    #Since we are encoding object datatype to integer/float\n",
    "            lbl = LabelEncoder()\n",
    "            lbl.fit(list(df[c].values))\n",
    "            df[c] = lbl.transform(df[c].values)\n",
    "    print(df.head())  #To check if properly encoded\n",
    "    \n",
    "    X = df[['Contract', 'tenure', 'TechSupport', 'OnlineSecurity', 'TotalCharges', 'PaperlessBilling',\n",
    "       'DeviceProtection', 'Dependents', 'OnlineBackup', 'SeniorCitizen', 'MonthlyCharges',\n",
    "       'PaymentMethod', 'Partner', 'PhoneService']] #taking only relevant columns\n",
    "    Y = df['Churn']\n",
    "\n",
    "\n",
    "    # Scaling all the variables to a range of 0 to 1\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    features = X.columns.values\n",
    "    scaler = MinMaxScaler(feature_range = (0,1))\n",
    "    scaler.fit(X)\n",
    "    X = pd.DataFrame(scaler.transform(X))\n",
    "    X.columns = features\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=101)\n",
    "    \n",
    "    aiplatform.init(\n",
    "       project=in_vertexai_projectid,\n",
    "       location=in_vertexai_region,\n",
    "       experiment=in_experiment_name\n",
    "    )\n",
    "    \n",
    "    run_id = f\"run-{idn}-{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "    aiplatform.start_run(run_id)\n",
    "    \n",
    "    #Choose which model to train\n",
    "    if model_type == 'svm':\n",
    "        from sklearn import svm\n",
    "        model = svm.LinearSVC()\n",
    "        \n",
    "    elif model_type == 'random_forrest':\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        model = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=0)\n",
    "        \n",
    "    elif model_type == 'decision_tree':\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        model = DecisionTreeClassifier()\n",
    "        \n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    artifact_filename = 'model.pkl'\n",
    "    local_path = artifact_filename\n",
    "    with open(local_path, 'wb') as model_file:\n",
    "      pickle.dump(model, model_file)\n",
    "    \n",
    "     \n",
    "    saved_model_path = os.path.join(saved_model.path.replace('/gcs', 'gs:/').replace(\"saved_model\",\"\"), artifact_filename)\n",
    "    blob = storage.blob.Blob.from_string(saved_model_path, client=storage.Client())\n",
    "    blob.upload_from_filename(local_path)\n",
    "    #joblib.dump(model, saved_model_path)\n",
    "\n",
    "     \n",
    "    predicted = model.predict(X_test)\n",
    "    \n",
    "    print(\"accuracy: {}\".format(metrics.accuracy_score(Y_test, predicted)))\n",
    "    print(\"f1 score macro: {}\".format(metrics.f1_score(Y_test, predicted, average='macro')   )  )\n",
    "    print(\"f1 score micro: {}\".format(metrics.f1_score(Y_test, predicted, average='micro') ))\n",
    "    print(\"precision score: {}\".format(metrics.precision_score(Y_test, predicted, average='macro') ))\n",
    "    print(\"recall score: {}\".format(metrics.recall_score(Y_test, predicted, average='macro') ))\n",
    "    print(\"hamming_loss: {}\".format(metrics.hamming_loss(Y_test, predicted)))\n",
    "    print(\"log_loss: {}\".format(metrics.log_loss(Y_test, predicted)))\n",
    "    print(\"zero_one_loss: {}\".format(metrics.zero_one_loss(Y_test, predicted)))\n",
    "    print(\"AUC&ROC: {}\".format(metrics.roc_auc_score(Y_test, predicted)))\n",
    "    print(\"matthews_corrcoef: {}\".format(metrics.matthews_corrcoef(Y_test, predicted) ))\n",
    "    \n",
    "    \n",
    "    training_params = {\n",
    "        'training_set': in_experiment_training_set,\n",
    "        'model_type': model_type,\n",
    "        'dataset_path': in_csv_path,\n",
    "        'model_path': saved_model_path\n",
    "    }\n",
    "    \n",
    "    training_metrics = {\n",
    "        'model_accuracy': metrics.accuracy_score(Y_test, predicted),\n",
    "        'model_precision': metrics.precision_score(Y_test, predicted, average='macro'),\n",
    "        'model_recall': metrics.recall_score(Y_test, predicted, average='macro'),\n",
    "        'model_logloss': metrics.log_loss(Y_test, predicted),\n",
    "        'model_auc_roc': metrics.roc_auc_score(Y_test, predicted)\n",
    "    }\n",
    "    \n",
    "    aiplatform.log_params(training_params)\n",
    "    aiplatform.log_metrics(training_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8195b0b3-1cf4-4655-a057-9b2814a0e45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "@component(\n",
    "   packages_to_install=[\"pandas\", \"google-cloud-aiplatform\"]\n",
    ")\n",
    "def gate(in_experiment_name: str,\n",
    "         in_experiment_training_set: str,\n",
    "         in_vertexai_region: str,\n",
    "         in_vertexai_projectid: str\n",
    "        )-> NamedTuple(\n",
    "           'winner_output',\n",
    "            [\n",
    "                ('experiment_info', str),\n",
    "                ('is_current_champion', bool)\n",
    "            ]\n",
    "        ):\n",
    "    \n",
    "    from google.cloud import aiplatform\n",
    "    import json\n",
    "    from collections import namedtuple\n",
    "    \n",
    "    aiplatform.init(\n",
    "       project=      in_vertexai_projectid,\n",
    "       location=     in_vertexai_region,\n",
    "       experiment =  in_experiment_name\n",
    "    )\n",
    "    \n",
    "\n",
    "    ## get vertex AI model object corresponding to <champion model> from ModelRegistry - use labels: experiment_name \n",
    "    champion_model = None\n",
    "    champion_model_exists = False\n",
    "    \n",
    "    model_filter_str='labels.experiment_name=\"'+in_experiment_name+'\"'\n",
    "    print(\"Model filter string: \"+model_filter_str)\n",
    "    \n",
    "    models = aiplatform.Model.list(\n",
    "        filter=model_filter_str\n",
    "    )\n",
    "    \n",
    "    if len(models)>0:\n",
    "        champion_model_exists = True\n",
    "        champion_model = models[0]\n",
    "        print(champion_model.display_name)\n",
    "        champion_model_experiment_run_id = champion_model.labels['experiment_run_id']\n",
    "    \n",
    "    \n",
    "    ## fetch experiment run details for current <training set>:\n",
    "    experiment_df = aiplatform.get_experiment_df()\n",
    "    experiment_df = experiment_df[experiment_df.experiment_name == in_experiment_name]\n",
    "    \n",
    "    \n",
    "    challengers_experiment_run_info =  experiment_df[experiment_df[\"param.training_set\"] == in_experiment_training_set]\n",
    "    \n",
    "    print(\"Challengers:\")\n",
    "    print(challengers_experiment_run_info.to_string())\n",
    "    \n",
    "    if champion_model != None:\n",
    "       current_champion_experiment_run_info = experiment_df[experiment_df[\"run_name\"] == champion_model_experiment_run_id]\n",
    "    \n",
    "    decision_metric_name = \"metric.model_auc_roc\"\n",
    "    \n",
    "    ### fetch best experiment_run_id from challengers\n",
    "    best_challenger_experiment_run_info = challengers_experiment_run_info[\n",
    "        challengers_experiment_run_info[decision_metric_name]==challengers_experiment_run_info[decision_metric_name].max()\n",
    "    ]\n",
    "    \n",
    "    print(\"Best challenger\")\n",
    "    print(best_challenger_experiment_run_info.to_string())\n",
    "    \n",
    "    winner_experiment_run_info = None\n",
    "    \n",
    "    winner_is_current_champion = False\n",
    "    if champion_model != None: \n",
    "        winner_experiment_run_info = current_champion_experiment_run_info\n",
    "        winner_is_current_champion = True\n",
    "        \n",
    "        ## Final: best_challenger vs champion\n",
    "        if best_challenger_experiment_run_info[decision_metric_name].values[0]>current_champion_experiment_run_info[decision_metric_name].values[0]:\n",
    "            ## best challenger is the new winner\n",
    "            winner_experiment_run_info = best_challenger_experiment_run_info\n",
    "            winner_is_current_champion = False\n",
    "    else: \n",
    "        winner_experiment_run_info = best_challenger_experiment_run_info\n",
    "        winner_is_current_champion = False\n",
    "    \n",
    "    winner_experiment_info = {\n",
    "           \"experiment_name\": winner_experiment_run_info[\"experiment_name\"].values[0],\n",
    "           \"experiment_run_id\": winner_experiment_run_info[\"run_name\"].values[0]\n",
    "    }\n",
    "    \n",
    "    print(\"winner:\")\n",
    "    print(winner_experiment_info)\n",
    "    \n",
    "    ##https://www.kubeflow.org/docs/components/pipelines/sdk/python-function-components/#pass-by-file\n",
    "    winner_namedtuple = namedtuple('winner_output', ['experiment_info', 'is_current_champion'])\n",
    "    \n",
    "    return winner_namedtuple(json.dumps(winner_experiment_info), winner_is_current_champion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a28dd2a1-0c7e-44c0-a256-171a7a8f71b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(packages_to_install=[\"google-cloud-aiplatform\",\n",
    "                                \"google-cloud-pipeline-components\",\n",
    "                                \"typing\",\n",
    "                                'datetime'\n",
    "                               ], base_image = \"python:3.7\"\n",
    "    \n",
    ")\n",
    "def deploy(in_experiment_name: str, \n",
    "           in_experiment_training_set: str, \n",
    "           in_vertexai_region: str, \n",
    "           in_vertexai_projectid: str,\n",
    "           eval_info: str, #evaluation_gate_task.outputs['experiment_info']\n",
    "           in_vertex_serving_machine_type: str,\n",
    "           in_vertex_serving_min_replicas: int,\n",
    "           in_vertex_serving_max_replica: int\n",
    "          ):\n",
    "            \n",
    "        from typing import Union\n",
    "        from typing import Dict\n",
    "        from google.cloud import aiplatform\n",
    "        from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "        import json\n",
    "        \n",
    "        from datetime import datetime\n",
    "        TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "        \n",
    "        aiplatform.init(\n",
    "            project=      in_vertexai_projectid,\n",
    "            location=     in_vertexai_region,\n",
    "            experiment =  in_experiment_name\n",
    "    )\n",
    "\n",
    "        #x=json.loads(eval_info)\n",
    "        \n",
    "        experiment=json.loads(eval_info)['experiment_name']\n",
    "        run_name=json.loads(eval_info)['experiment_run_id']\n",
    "        \n",
    "        def get_experiment_run_params_sample(\n",
    "            run_name: str,\n",
    "            experiment: Union[str, aiplatform.Experiment],\n",
    "            project: str,\n",
    "            location: str,\n",
    "        ) -> Dict[str, Union[float, int, str]]:\n",
    "            experiment_run = aiplatform.ExperimentRun(\n",
    "                run_name=run_name, experiment=experiment, project=project, location=location\n",
    "            )\n",
    "            return experiment_run.get_params()\n",
    "\n",
    "        results_dict=get_experiment_run_params_sample(run_name, \n",
    "                                 experiment,\n",
    "                                 'laah-play', \n",
    "                                 'us-central1')\n",
    "            \n",
    "        artifact_uri=results_dict['model_path'].replace(\"saved_model\",\"\").replace('model.pkl','')\n",
    "            \n",
    "        model = aiplatform.Model.upload(\n",
    "            project=in_vertexai_projectid,\n",
    "            display_name=\"model\"+TIMESTAMP, \n",
    "            artifact_uri=artifact_uri, # GCS location of model\n",
    "            serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest\"\n",
    "        )\n",
    "        \n",
    "        endpoint = aiplatform.Endpoint.create(\n",
    "        display_name=\"pipelines\"+TIMESTAMP,\n",
    "        project=in_vertexai_projectid,\n",
    "        location=in_vertexai_region)\n",
    "        \n",
    "        model.deploy(\n",
    "            endpoint=endpoint,\n",
    "            deployed_model_display_name=\"model\"+TIMESTAMP,\n",
    "            machine_type=\"n1-standard-4\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad5b9462-18a0-42c5-8842-4ad1d6592fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(name=\"wf-churn\")\n",
    "def pipeline(\n",
    "    in_bigquery_projectid: str = 'laah-play',\n",
    "    in_bigquery_dataset: str = 'telcosandbox',\n",
    "    in_corr_threshold: float = 0.05,\n",
    "    in_experiment_name: str = \"telcochurn10\",\n",
    "    in_experiment_training_set: str = \"telcochurn\",\n",
    "    in_vertexai_projectid: str = \"laah-play\",\n",
    "    in_vertexai_region: str = \"us-central1\",\n",
    "    in_vertex_serving_machine_type: str = \"n1-standard-4\",\n",
    "    in_vertex_serving_min_replicas: int = 1,\n",
    "    in_vertex_serving_max_replicas: int = 2,\n",
    "    values: list = ['svm', 'random_forrest', 'decision_tree']\n",
    "    \n",
    "):\n",
    "    \n",
    "    import json\n",
    "    \n",
    "    #### STEP1: PREPROCESSING\n",
    "    staging_task = preprocess(in_bigquery_projectid,\n",
    "                         in_bigquery_dataset\n",
    "                        )\n",
    "    \n",
    "    \n",
    "    ### STEP2: TRAIN CHALLENGERS\n",
    "    with ParallelFor(values) as item:\n",
    "        train_task =            train(in_experiment_name, \n",
    "                                      in_experiment_training_set, \n",
    "                                      in_vertexai_region, \n",
    "                                      in_vertexai_projectid, \n",
    "                                      staging_task.output, \n",
    "                                      item\n",
    "                                     )\n",
    "        \n",
    "        #### STEP3: GATE - Identify best challenger and compare with current champion\n",
    "    evaluation_gate_task = gate(in_experiment_name, \n",
    "                                in_experiment_training_set, \n",
    "                                in_vertexai_region, \n",
    "                                in_vertexai_projectid).after(train_task)\n",
    "     \n",
    "    \n",
    "    with Condition(\n",
    "        evaluation_gate_task.outputs['is_current_champion'] == \"false\", \n",
    "        name=\"deploy_new_champion\"\n",
    "    ): \n",
    "        ### STEP 5&6 Register new Chamption and deploy it to endpoint\n",
    "        result = deploy(in_experiment_name, \n",
    "                        in_experiment_training_set, \n",
    "                        in_vertexai_region, \n",
    "                        in_vertexai_projectid,\n",
    "                        evaluation_gate_task.outputs['experiment_info'],\n",
    "                        in_vertex_serving_machine_type,\n",
    "                        in_vertex_serving_min_replicas,\n",
    "                        in_vertex_serving_max_replicas\n",
    "                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db2ee4e5-6aca-4e4e-871d-e9adf6e8718e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1266: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline, package_path=\"custom_model_training_spec.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "726ed112-8252-4af9-9402-669393a86601",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISPLAY_NAME = \"cifar10_\" + TIMESTAMP\n",
    "\n",
    "job = aip.PipelineJob(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    template_path=\"custom_model_training_spec.json\",\n",
    "    pipeline_root=PIPELINE_ROOT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af7e3a2d-878f-4bde-848d-0178f0be4f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/959641146622/locations/us-central1/pipelineJobs/wf-churn-20220921150726\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/959641146622/locations/us-central1/pipelineJobs/wf-churn-20220921150726')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/wf-churn-20220921150726?project=959641146622\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/959641146622/locations/us-central1/pipelineJobs/wf-churn-20220921150726 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/959641146622/locations/us-central1/pipelineJobs/wf-churn-20220921150726 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/959641146622/locations/us-central1/pipelineJobs/wf-churn-20220921150726 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [for-loop-1].; Job (project_id = laah-play, job_id = 6180364755333545984) is failed due to the above error.; Failed to handle the job: {project_number = 959641146622, job_id = 6180364755333545984}\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12979/4143958703.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m                     \u001b[0mVertexAiResourceNounWithFutureManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0;31m# callbacks to call within the Future (in same Thread)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, service_account, network, sync)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice_account\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice_account\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     def submit(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36m_block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;31m# JOB_STATE_FAILED or JOB_STATE_CANCELLED.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_PIPELINE_ERROR_STATES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job failed with:\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_action_completed_against_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [for-loop-1].; Job (project_id = laah-play, job_id = 6180364755333545984) is failed due to the above error.; Failed to handle the job: {project_number = 959641146622, job_id = 6180364755333545984}\"\n"
     ]
    }
   ],
   "source": [
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dc7ef6-31ac-44ec-a794-0d5ed624057f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
